{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db19c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO,BytesIO\n",
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf66c7",
   "metadata": {},
   "source": [
    "# Adapter Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739ac716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_df(bucket,key,decoding='utf-8',sep=','):\n",
    "    csv_obj=bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
    "    data=StringIO(csv_obj)\n",
    "    df=pd.read_csv(data,delimiter=sep)\n",
    "    return df\n",
    "\n",
    "def write_df_to_s3(bucket,df,key):\n",
    "    out_buffer=BytesIO()\n",
    "    df.to_parquet(out_buffer,index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(),Key=key)\n",
    "    return True\n",
    "\n",
    "def write_df_to_s3_csv(bucket,df,key):\n",
    "    out_buffer=StringIO()\n",
    "    df.to_csv(out_buffer,index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(),Key=key)\n",
    "    return True\n",
    "\n",
    "def list_files_in_prefix(bucket,prefix):\n",
    "    files = [obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79fdf5b",
   "metadata": {},
   "source": [
    "# Application Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4787192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(bucket,date_list):\n",
    "    files = [key for date in date_list for key in list_files_in_prefix(bucket,date)]\n",
    "    df=pd.concat([read_csv_to_df(bucket,obj) for obj in files],ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def transform_report1(df,columns,arg_date):\n",
    "    df=df.loc[:,columns]\n",
    "    df.dropna(inplace=True)\n",
    "    df['opening_price']=df.sort_values(by=['Time']).groupby(['ISIN','Date'])['StartPrice'].transform('first')\n",
    "    df['closing_price']=df.sort_values(by=['Time']).groupby(['ISIN','Date'])['StartPrice'].transform('last')\n",
    "    df=df.groupby(['ISIN','Date'],as_index=False).agg(opening_price_eur=('opening_price','min'),\n",
    "                                                         closing_price_eur=('closing_price','min'),\n",
    "                                                         minimum_price_eur=('MinPrice','min'),\n",
    "                                                         maximum_price_eur=('MaxPrice','max'),\n",
    "                                                         daily_traded_volumne=('TradedVolume','sum'))\n",
    "    df['prev_closing_price']=df.sort_values(by=['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
    "    df['change_prev_closing_%']=(df['closing_price_eur']-df['prev_closing_price'])/df['prev_closing_price']*100\n",
    "    df.drop(columns=['prev_closing_price'],inplace=True)\n",
    "    df=df.round(decimals=2)\n",
    "    df=df[df.Date>=arg_date]\n",
    "    return df\n",
    "\n",
    "def load(bucket,df,trg_key,trg_format,meta_key,extract_date_list):\n",
    "    key=trg_key+datetime.today().strftime('%Y%m%d_%H%M%S')+trg_format\n",
    "    write_df_to_s3(bucket,df,key)\n",
    "    # once the data is loaded update the meta file\n",
    "    update_meta_file(bucket,meta_key,extract_date_list)\n",
    "    return True\n",
    "\n",
    "def etl_report1(src_bucket,trg_bucket,date_list,columns,arg_date,trg_key,trg_format,meta_key):\n",
    "    df=extract(src_bucket,date_list)\n",
    "    df=transform_report1(df,columns,arg_date)\n",
    "    \"\"\"\n",
    "    date_list: it contains the list from the first date we want to extract,minus one from first date\n",
    "    arg_date: first date we want to extract\n",
    "    \"\"\"\n",
    "    extract_date_list = [date for date in date_list if date>=arg_date]\n",
    "    load(trg_bucket,df,trg_key,trg_format,meta_key,extract_date_list)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b0697",
   "metadata": {},
   "source": [
    "# Application Layer - not core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc18fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fuction gives unprocessed dates\n",
    "def return_date_list(bucket,arg_date,src_format,meta_key):\n",
    "    min_date=datetime.strptime(arg_date,src_format).date()-timedelta(days=1)\n",
    "    today=datetime.today().date()\n",
    "    # try block will run if we have metafile\n",
    "    try:\n",
    "        df_meta=read_csv_to_df(bucket,meta_key)\n",
    "        # converting string to dates\n",
    "        dates = [(min_date+timedelta(days=x)) for x in range(0,(today-min_date).days+1)]\n",
    "        src_dates=set(pd.to_datetime(df_meta['source_date']).dt.date)\n",
    "        # checking if all the files have been processed or not\n",
    "        date_missing=set(dates[1:])-src_dates\n",
    "        if date_missing: # if all dates data has been processed then \n",
    "            min_date=min(set(return_date_list[1:])-src_dates)-timedelta(days=1)\n",
    "            # converting dates to strings\n",
    "            return_dates=[date.strftime(src_format) for date in return_date_list if date>=min_date]\n",
    "            return_min_date=(min_date+timedelta(days=1)).strftime(src_format)\n",
    "        else:\n",
    "            return_dates=[]\n",
    "            return_min_date=datetime(2200,1,1).date()\n",
    "    except:\n",
    "        # if there is no meta-data then return all dates since min_date untill today\n",
    "        return_dates = [(min_date+timedelta(days=x)).strftime(src_format) for x in range(0,(today-min_date).days+1)]\n",
    "        # if there job is runing for first time and there is no process date then arg_date will be min date\n",
    "        return_min_date=arg_date\n",
    "    return return_min_date,return_dates\n",
    "\n",
    "def update_meta_file(bucket,meta_key,extract_date_list):\n",
    "    \"\"\"\n",
    "    extract_date_list: list of dates that need to be update.\n",
    "    \"\"\"\n",
    "    df_new=pd.DataFrame(columns=['source_date','datetime_of_processing'])\n",
    "    df_new['source_date']=extract_date_list\n",
    "    df_new['datetime_of_processing']=datetime.today().strftime('%Y-%m-%d')\n",
    "    # reading the existing metafile\n",
    "    df_old=read_csv_to_df(bucket,meta_key)\n",
    "    # updated dataframe\n",
    "    df_all=pd.concat([df_old,df_new])\n",
    "    write_df_to_s3_csv(bucket,df_all,meta_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae19531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main fuction entrypoint\n",
    "def main():\n",
    "    trg_key='xetra_daily_report_'\n",
    "    trg_format='.parquet'\n",
    "    arg_date='2022-01-25'\n",
    "    src_format='%Y-%m-%d'\n",
    "    src_bucket='deutsche-boerse-xetra-pds'\n",
    "    trg_bucket='xetra-bucket-proj'\n",
    "    columns=['ISIN','Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice','EndPrice', 'TradedVolume']\n",
    "    meta_key='meta_file.csv'\n",
    "    \n",
    "    # init\n",
    "    s3 = boto3.resource('s3',aws_access_key_id=\"AKIAR7554OTXIHAAMCD6\",\n",
    "                         aws_secret_access_key=\"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\")\n",
    "    bucket_src = s3.Bucket(src_bucket)\n",
    "    bucket_trg = s3.Bucket(trg_bucket)\n",
    "    \n",
    "    # run application\n",
    "    extract_date,date_list = return_date_list(bucket_trg ,arg_date ,src_format,meta_key)\n",
    "    etl_report1(bucket_src ,bucket_trg,date_list ,columns ,extract_date ,trg_key ,trg_format, meta_key)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343356e9",
   "metadata": {},
   "source": [
    "# Reading the uploaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959cb5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta/\n",
      "meta/meta_file.csv\n",
      "meta/report1/\n",
      "meta/report1/xetra_report1_meta_file.csv\n",
      "report1/\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "trg_bucket='xetra-bucket-proj'\n",
    "s3 = boto3.resource('s3',aws_access_key_id=\"AKIAR7554OTXIHAAMCD6\",\n",
    "                         aws_secret_access_key=\"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\")\n",
    "bucket_trg = s3.Bucket(trg_bucket)\n",
    "for obj in bucket_trg.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50623b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>opening_price_eur</th>\n",
       "      <th>closing_price_eur</th>\n",
       "      <th>minimum_price_eur</th>\n",
       "      <th>maximum_price_eur</th>\n",
       "      <th>daily_traded_volumne</th>\n",
       "      <th>change_prev_closing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>36.05</td>\n",
       "      <td>35.85</td>\n",
       "      <td>35.85</td>\n",
       "      <td>36.05</td>\n",
       "      <td>420</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7.26</td>\n",
       "      <td>360</td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT0000606306</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.72</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.72</td>\n",
       "      <td>1776</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT0000644505</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>107.40</td>\n",
       "      <td>108.00</td>\n",
       "      <td>107.20</td>\n",
       "      <td>108.00</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT0000652011</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>41.31</td>\n",
       "      <td>41.49</td>\n",
       "      <td>41.13</td>\n",
       "      <td>41.49</td>\n",
       "      <td>1867</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ISIN        Date  opening_price_eur  closing_price_eur  \\\n",
       "0  AT000000STR1  2022-01-25              36.05              35.85   \n",
       "1  AT00000FACC2  2022-01-25               7.26               7.26   \n",
       "2  AT0000606306  2022-01-25              23.30              23.72   \n",
       "3  AT0000644505  2022-01-25             107.40             108.00   \n",
       "4  AT0000652011  2022-01-25              41.31              41.49   \n",
       "\n",
       "   minimum_price_eur  maximum_price_eur  daily_traded_volumne  \\\n",
       "0              35.85              36.05                   420   \n",
       "1               7.26               7.26                   360   \n",
       "2              23.30              23.72                  1776   \n",
       "3             107.20             108.00                    80   \n",
       "4              41.13              41.49                  1867   \n",
       "\n",
       "   change_prev_closing_%  \n",
       "0                   1.85  \n",
       "1                  -0.68  \n",
       "2                   2.68  \n",
       "3                  -0.18  \n",
       "4                   2.14  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prq_obj=bucket_trg.Object(key=\"xetra_daily_report_20220125_143956.parquet\").get().get('Body').read()\n",
    "data=BytesIO(prq_obj)\n",
    "df_report=pd.read_parquet(data)\n",
    "\n",
    "df_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a77274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
